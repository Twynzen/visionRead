# SnapSight AI ğŸ“¸ğŸ§ 

> Transform screenshots into accessible content with AI-powered vision and voice

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Angular](https://img.shields.io/badge/Angular-17+-red.svg)](https://angular.io/)
[![OpenAI](https://img.shields.io/badge/OpenAI-GPT--4--Vision-412991.svg)](https://openai.com/)

## ğŸ¯ What is SnapSight?

SnapSight is an AI-powered web application that makes visual content accessible to everyone. Capture any part of your screen, and our AI will:

- ğŸ“ **Extract all text** (OCR) from images
- ğŸ” **Analyze visual content** with GPT-4 Vision
- ğŸ“„ **Generate formatted Markdown** documentation
- ğŸ”Š **Convert to natural speech** for audio playback

Perfect for accessibility, documentation, research, and learning.

## âœ¨ Features

- **Instant Screen Capture** - Browser-native screen recording API
- **AI Vision Analysis** - Powered by OpenAI GPT-4 Vision
- **Smart OCR** - Extract text from any image automatically
- **Text-to-Speech** - Natural voice synthesis with OpenAI TTS
- **Markdown Export** - Save analysis as formatted documents
- **Privacy First** - Secure API handling, no data storage

## ğŸ† Built for YuKeSong2025 Hackathon

**Theme:** AI for Good
**Goal:** Make visual information accessible to everyone

## ğŸš€ Quick Start

### Prerequisites

- Node.js 18+ and npm
- OpenAI API key

### Installation

```bash
# Clone the repository
git clone https://github.com/Twynzen/visionRead.git
cd visionRead

# Install dependencies
npm install

# Configure environment
cp .env.example .env
# Add your OPENAI_API_KEY to .env

# Run development server
npm start
```

Visit `http://localhost:4200`

## ğŸ› ï¸ Tech Stack

- **Frontend:** Angular 17+ (Standalone Components)
- **UI:** Angular Material
- **AI:** OpenAI GPT-4 Vision + TTS
- **Backend:** Vercel Serverless Functions
- **Deployment:** Vercel

## ğŸ“¦ Project Structure

```
snapsight/
â”œâ”€â”€ src/app/
â”‚   â”œâ”€â”€ components/      # UI components
â”‚   â”œâ”€â”€ services/        # Business logic
â”‚   â””â”€â”€ models/          # TypeScript interfaces
â”œâ”€â”€ api/                 # Serverless functions
â””â”€â”€ public/              # Static assets
```

## ğŸ¨ How It Works

1. **Capture** - Click to capture any screen area
2. **Analyze** - AI analyzes the image content
3. **Read** - View results as text and markdown
4. **Listen** - Play audio version with natural voice

## ğŸ¤ Contributing

This is a hackathon project built for YuKeSong2025. Contributions, issues, and feature requests are welcome!

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file for details

## ğŸ‘¥ Team

Built with by:
- **Daniel** - Development & Architecture
- **Claude** - AI Assistant & Code Generation

## ğŸ™ Acknowledgments

- YuKeSong2025 Hackathon organizers
- OpenAI for Vision and TTS APIs
- Angular and Vercel teams

---

**Made with for AI for Good** ğŸŒŸ
